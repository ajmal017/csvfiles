{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSoa1mZANhHV4om472fnKf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/animalran/csvfiles/blob/master/Untitled15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4dBwOD-ulG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Yahoo! Finance market data downloader (+fix for Pandas Datareader)\n",
        "# https://github.com/ranaroussi/yfinance\n",
        "#\n",
        "# Copyright 2017-2019 Ran Aroussi\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "#\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import time as _time\n",
        "import datetime as _datetime\n",
        "import requests as _requests\n",
        "import pandas as _pd\n",
        "import numpy as _np\n",
        "\n",
        "try:\n",
        "    from urllib.parse import quote as urlencode\n",
        "except ImportError:\n",
        "    from urllib import quote as urlencode\n",
        "\n",
        "from . import utils\n",
        "\n",
        "# import json as _json\n",
        "# import re as _re\n",
        "# import sys as _sys\n",
        "\n",
        "from . import shared\n",
        "\n",
        "\n",
        "class TickerBase():\n",
        "    def __init__(self, ticker):\n",
        "        self.ticker = ticker.upper()\n",
        "        self._history = None\n",
        "        self._base_url = 'https://query1.finance.yahoo.com'\n",
        "        self._scrape_url = 'https://finance.yahoo.com/quote'\n",
        "\n",
        "        self._fundamentals = False\n",
        "        self._info = None\n",
        "        self._sustainability = None\n",
        "        self._recommendations = None\n",
        "        self._major_holders = None\n",
        "        self._institutional_holders = None\n",
        "        self._isin = None\n",
        "\n",
        "        self._calendar = None\n",
        "        self._expirations = {}\n",
        "\n",
        "        self._earnings = {\n",
        "            \"yearly\": utils.empty_df(),\n",
        "            \"quarterly\": utils.empty_df()}\n",
        "        self._financials = {\n",
        "            \"yearly\": utils.empty_df(),\n",
        "            \"quarterly\": utils.empty_df()}\n",
        "        self._balancesheet = {\n",
        "            \"yearly\": utils.empty_df(),\n",
        "            \"quarterly\": utils.empty_df()}\n",
        "        self._cashflow = {\n",
        "            \"yearly\": utils.empty_df(),\n",
        "            \"quarterly\": utils.empty_df()}\n",
        "\n",
        "    def history(self, period=\"1mo\", interval=\"1d\",\n",
        "                start=None, end=None, prepost=False, actions=True,\n",
        "                auto_adjust=True, back_adjust=False,\n",
        "                proxy=None, rounding=True, tz=None, **kwargs):\n",
        "        \"\"\"\n",
        "        :Parameters:\n",
        "            period : str\n",
        "                Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
        "                Either Use period parameter or use start and end\n",
        "            interval : str\n",
        "                Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
        "                Intraday data cannot extend last 60 days\n",
        "            start: str\n",
        "                Download start date string (YYYY-MM-DD) or _datetime.\n",
        "                Default is 1900-01-01\n",
        "            end: str\n",
        "                Download end date string (YYYY-MM-DD) or _datetime.\n",
        "                Default is now\n",
        "            prepost : bool\n",
        "                Include Pre and Post market data in results?\n",
        "                Default is False\n",
        "            auto_adjust: bool\n",
        "                Adjust all OHLC automatically? Default is True\n",
        "            back_adjust: bool\n",
        "                Back-adjusted data to mimic true historical prices\n",
        "            proxy: str\n",
        "                Optional. Proxy server URL scheme. Default is None\n",
        "            rounding: bool\n",
        "                Round values to 2 decimal places?\n",
        "                Optional. Default is False = precision suggested by Yahoo!\n",
        "            tz: str\n",
        "                Optional timezone locale for dates.\n",
        "                (default data is returned as non-localized dates)\n",
        "            **kwargs: dict\n",
        "                debug: bool\n",
        "                    Optional. If passed as False, will suppress\n",
        "                    error message printing to console.\n",
        "        \"\"\"\n",
        "\n",
        "        if start or period is None or period.lower() == \"max\":\n",
        "            if start is None:\n",
        "                start = -2208988800\n",
        "            elif isinstance(start, _datetime.datetime):\n",
        "                start = int(_time.mktime(start.timetuple()))\n",
        "            else:\n",
        "                start = int(_time.mktime(\n",
        "                    _time.strptime(str(start), '%Y-%m-%d')))\n",
        "            if end is None:\n",
        "                end = int(_time.time())\n",
        "            elif isinstance(end, _datetime.datetime):\n",
        "                end = int(_time.mktime(end.timetuple()))\n",
        "            else:\n",
        "                end = int(_time.mktime(_time.strptime(str(end), '%Y-%m-%d')))\n",
        "\n",
        "            params = {\"period1\": start, \"period2\": end}\n",
        "        else:\n",
        "            period = period.lower()\n",
        "            params = {\"range\": period}\n",
        "\n",
        "        params[\"interval\"] = interval.lower()\n",
        "        params[\"includePrePost\"] = prepost\n",
        "        params[\"events\"] = \"div,splits\"\n",
        "\n",
        "        # 1) fix weired bug with Yahoo! - returning 60m for 30m bars\n",
        "        if params[\"interval\"] == \"30m\":\n",
        "            params[\"interval\"] = \"15m\"\n",
        "\n",
        "        # setup proxy in requests format\n",
        "        if proxy is not None:\n",
        "            if isinstance(proxy, dict) and \"https\" in proxy:\n",
        "                proxy = proxy[\"https\"]\n",
        "            proxy = {\"https\": proxy}\n",
        "\n",
        "        # Getting data from json\n",
        "        url = \"{}/v8/finance/chart/{}\".format(self._base_url, self.ticker)\n",
        "        data = _requests.get(url=url, params=params, proxies=proxy)\n",
        "        if \"Will be right back\" in data.text:\n",
        "            raise RuntimeError(\"*** YAHOO! FINANCE IS CURRENTLY DOWN! ***\\n\"\n",
        "                               \"Our engineers are working quickly to resolve \"\n",
        "                               \"the issue. Thank you for your patience.\")\n",
        "        data = data.json()\n",
        "\n",
        "        # Work with errors\n",
        "        debug_mode = True\n",
        "        if \"debug\" in kwargs and isinstance(kwargs[\"debug\"], bool):\n",
        "            debug_mode = kwargs[\"debug\"]\n",
        "\n",
        "        err_msg = \"No data found for this date range, symbol may be delisted\"\n",
        "        if \"chart\" in data and data[\"chart\"][\"error\"]:\n",
        "            err_msg = data[\"chart\"][\"error\"][\"description\"]\n",
        "            shared._DFS[self.ticker] = utils.empty_df()\n",
        "            shared._ERRORS[self.ticker] = err_msg\n",
        "            if \"many\" not in kwargs and debug_mode:\n",
        "                print('- %s: %s' % (self.ticker, err_msg))\n",
        "            return shared._DFS[self.ticker]\n",
        "\n",
        "        elif \"chart\" not in data or data[\"chart\"][\"result\"] is None or \\\n",
        "                not data[\"chart\"][\"result\"]:\n",
        "            shared._DFS[self.ticker] = utils.empty_df()\n",
        "            shared._ERRORS[self.ticker] = err_msg\n",
        "            if \"many\" not in kwargs and debug_mode:\n",
        "                print('- %s: %s' % (self.ticker, err_msg))\n",
        "            return shared._DFS[self.ticker]\n",
        "\n",
        "        # parse quotes\n",
        "        try:\n",
        "            quotes = utils.parse_quotes(data[\"chart\"][\"result\"][0], tz)\n",
        "        except Exception:\n",
        "            shared._DFS[self.ticker] = utils.empty_df()\n",
        "            shared._ERRORS[self.ticker] = err_msg\n",
        "            if \"many\" not in kwargs and debug_mode:\n",
        "                print('- %s: %s' % (self.ticker, err_msg))\n",
        "            return shared._DFS[self.ticker]\n",
        "\n",
        "        # 2) fix weired bug with Yahoo! - returning 60m for 30m bars\n",
        "        if interval.lower() == \"30m\":\n",
        "            quotes2 = quotes.resample('30T')\n",
        "            quotes = _pd.DataFrame(index=quotes2.last().index, data={\n",
        "                'Open': quotes2['Open'].first(),\n",
        "                'High': quotes2['High'].max(),\n",
        "                'Low': quotes2['Low'].min(),\n",
        "                'Close': quotes2['Close'].last(),\n",
        "                'Adj Close': quotes2['Adj Close'].last(),\n",
        "                'Volume': quotes2['Volume'].sum()\n",
        "            })\n",
        "            try:\n",
        "                quotes['Dividends'] = quotes2['Dividends'].max()\n",
        "            except Exception:\n",
        "                pass\n",
        "            try:\n",
        "                quotes['Stock Splits'] = quotes2['Dividends'].max()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if auto_adjust:\n",
        "            quotes = utils.auto_adjust(quotes)\n",
        "        elif back_adjust:\n",
        "            quotes = utils.back_adjust(quotes)\n",
        "\n",
        "        if rounding:\n",
        "            quotes = _np.round(quotes, data[\n",
        "                \"chart\"][\"result\"][0][\"meta\"][\"priceHint\"])\n",
        "        quotes['Volume'] = quotes['Volume'].fillna(0).astype(_np.int64)\n",
        "\n",
        "        quotes.dropna(inplace=True)\n",
        "\n",
        "        # actions\n",
        "        dividends, splits = utils.parse_actions(data[\"chart\"][\"result\"][0], tz)\n",
        "\n",
        "        # combine\n",
        "        df = _pd.concat([quotes, dividends, splits], axis=1, sort=True)\n",
        "        df[\"Dividends\"].fillna(0, inplace=True)\n",
        "        df[\"Stock Splits\"].fillna(0, inplace=True)\n",
        "\n",
        "        # index eod/intraday\n",
        "        df.index = df.index.tz_localize(\"UTC\").tz_convert(\n",
        "            data[\"chart\"][\"result\"][0][\"meta\"][\"exchangeTimezoneName\"])\n",
        "\n",
        "        if params[\"interval\"][-1] == \"m\":\n",
        "            df.index.name = \"Datetime\"\n",
        "        else:\n",
        "            df.index = _pd.to_datetime(df.index.date)\n",
        "            if tz is not None:\n",
        "                df.index = df.index.tz_localize(tz)\n",
        "            df.index.name = \"Date\"\n",
        "\n",
        "        self._history = df.copy()\n",
        "\n",
        "        if not actions:\n",
        "            df.drop(columns=[\"Dividends\", \"Stock Splits\"], inplace=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "    # ------------------------\n",
        "\n",
        "    def _get_fundamentals(self, kind=None, proxy=None):\n",
        "        def cleanup(data):\n",
        "            df = _pd.DataFrame(data).drop(columns=['maxAge'])\n",
        "            for col in df.columns:\n",
        "                df[col] = _np.where(\n",
        "                    df[col].astype(str) == '-', _np.nan, df[col])\n",
        "\n",
        "            df.set_index('endDate', inplace=True)\n",
        "            try:\n",
        "                df.index = _pd.to_datetime(df.index, unit='s')\n",
        "            except ValueError:\n",
        "                df.index = _pd.to_datetime(df.index)\n",
        "            df = df.T\n",
        "            df.columns.name = ''\n",
        "            df.index.name = 'Breakdown'\n",
        "\n",
        "            df.index = utils.camel2title(df.index)\n",
        "            return df\n",
        "\n",
        "        # setup proxy in requests format\n",
        "        if proxy is not None:\n",
        "            if isinstance(proxy, dict) and \"https\" in proxy:\n",
        "                proxy = proxy[\"https\"]\n",
        "            proxy = {\"https\": proxy}\n",
        "\n",
        "        if self._fundamentals:\n",
        "            return\n",
        "\n",
        "        # get info and sustainability\n",
        "        url = '%s/%s' % (self._scrape_url, self.ticker)\n",
        "        data = utils.get_json(url, proxy)\n",
        "\n",
        "        # holders\n",
        "        url = \"{}/{}/holders\".format(self._scrape_url, self.ticker)\n",
        "        holders = _pd.read_html(url)\n",
        "        self._major_holders = holders[0]\n",
        "        self._institutional_holders = holders[1]\n",
        "        if 'Date Reported' in self._institutional_holders:\n",
        "            self._institutional_holders['Date Reported'] = _pd.to_datetime(\n",
        "                self._institutional_holders['Date Reported'])\n",
        "        if '% Out' in self._institutional_holders:\n",
        "            self._institutional_holders['% Out'] = self._institutional_holders[\n",
        "                '% Out'].str.replace('%', '').astype(float)/100\n",
        "\n",
        "        # sustainability\n",
        "        d = {}\n",
        "        if isinstance(data.get('esgScores'), dict):\n",
        "            for item in data['esgScores']:\n",
        "                if not isinstance(data['esgScores'][item], (dict, list)):\n",
        "                    d[item] = data['esgScores'][item]\n",
        "\n",
        "            s = _pd.DataFrame(index=[0], data=d)[-1:].T\n",
        "            s.columns = ['Value']\n",
        "            s.index.name = '%.f-%.f' % (\n",
        "                s[s.index == 'ratingYear']['Value'].values[0],\n",
        "                s[s.index == 'ratingMonth']['Value'].values[0])\n",
        "\n",
        "            self._sustainability = s[~s.index.isin(\n",
        "                ['maxAge', 'ratingYear', 'ratingMonth'])]\n",
        "\n",
        "        # info (be nice to python 2)\n",
        "        self._info = {}\n",
        "        items = ['summaryProfile', 'summaryDetail', 'quoteType',\n",
        "                 'defaultKeyStatistics', 'assetProfile', 'summaryDetail']\n",
        "        for item in items:\n",
        "            if isinstance(data.get(item), dict):\n",
        "                self._info.update(data[item])\n",
        "\n",
        "        self._info['regularMarketPrice'] = self._info['regularMarketOpen']\n",
        "        self._info['logo_url'] = \"\"\n",
        "        try:\n",
        "            domain = self._info['website'].split(\n",
        "                '://')[1].split('/')[0].replace('www.', '')\n",
        "            self._info['logo_url'] = 'https://logo.clearbit.com/%s' % domain\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # events\n",
        "        try:\n",
        "            cal = _pd.DataFrame(\n",
        "                data['calendarEvents']['earnings'])\n",
        "            cal['earningsDate'] = _pd.to_datetime(\n",
        "                cal['earningsDate'], unit='s')\n",
        "            self._calendar = cal.T\n",
        "            self._calendar.index = utils.camel2title(self._calendar.index)\n",
        "            self._calendar.columns = ['Value']\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # analyst recommendations\n",
        "        try:\n",
        "            rec = _pd.DataFrame(\n",
        "                data['upgradeDowngradeHistory']['history'])\n",
        "            rec['earningsDate'] = _pd.to_datetime(\n",
        "                rec['epochGradeDate'], unit='s')\n",
        "            rec.set_index('earningsDate', inplace=True)\n",
        "            rec.index.name = 'Date'\n",
        "            rec.columns = utils.camel2title(rec.columns)\n",
        "            self._recommendations = rec[[\n",
        "                'Firm', 'To Grade', 'From Grade', 'Action']].sort_index()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # get fundamentals\n",
        "        data = utils.get_json(url+'/financials', proxy)\n",
        "\n",
        "        # generic patterns\n",
        "        for key in (\n",
        "            (self._cashflow, 'cashflowStatement', 'cashflowStatements'),\n",
        "            (self._balancesheet, 'balanceSheet', 'balanceSheetStatements'),\n",
        "            (self._financials, 'incomeStatement', 'incomeStatementHistory')\n",
        "        ):\n",
        "\n",
        "            item = key[1] + 'History'\n",
        "            if isinstance(data.get(item), dict):\n",
        "                key[0]['yearly'] = cleanup(data[item][key[2]])\n",
        "\n",
        "            item = key[1]+'HistoryQuarterly'\n",
        "            if isinstance(data.get(item), dict):\n",
        "                key[0]['quarterly'] = cleanup(data[item][key[2]])\n",
        "\n",
        "        # earnings\n",
        "        if isinstance(data.get('earnings'), dict):\n",
        "            earnings = data['earnings']['financialsChart']\n",
        "            df = _pd.DataFrame(earnings['yearly']).set_index('date')\n",
        "            df.columns = utils.camel2title(df.columns)\n",
        "            df.index.name = 'Year'\n",
        "            self._earnings['yearly'] = df\n",
        "\n",
        "            df = _pd.DataFrame(earnings['quarterly']).set_index('date')\n",
        "            df.columns = utils.camel2title(df.columns)\n",
        "            df.index.name = 'Quarter'\n",
        "            self._earnings['quarterly'] = df\n",
        "\n",
        "        self._fundamentals = True\n",
        "\n",
        "    def get_recommendations(self, proxy=None, as_dict=False, *args, **kwargs):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._recommendations\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_calendar(self, proxy=None, as_dict=False, *args, **kwargs):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._calendar\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_major_holders(self, proxy=None, as_dict=False, *args, **kwargs):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._major_holders\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_institutional_holders(self, proxy=None, as_dict=False, *args, **kwargs):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._institutional_holders\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_info(self, proxy=None, as_dict=False, *args, **kwargs):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._info\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_sustainability(self, proxy=None, as_dict=False, *args, **kwargs):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._sustainability\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_earnings(self, proxy=None, as_dict=False, freq=\"yearly\"):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._earnings[freq]\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_financials(self, proxy=None, as_dict=False, freq=\"yearly\"):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._financials[freq]\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_balancesheet(self, proxy=None, as_dict=False, freq=\"yearly\"):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._balancesheet[freq]\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_balance_sheet(self, proxy=None, as_dict=False, freq=\"yearly\"):\n",
        "        return self.get_balancesheet(proxy, as_dict, freq)\n",
        "\n",
        "    def get_cashflow(self, proxy=None, as_dict=False, freq=\"yearly\"):\n",
        "        self._get_fundamentals(proxy)\n",
        "        data = self._cashflow[freq]\n",
        "        if as_dict:\n",
        "            return data.to_dict()\n",
        "        return data\n",
        "\n",
        "    def get_dividends(self, proxy=None):\n",
        "        if self._history is None:\n",
        "            self.history(period=\"max\", proxy=proxy)\n",
        "        dividends = self._history[\"Dividends\"]\n",
        "        return dividends[dividends != 0]\n",
        "\n",
        "    def get_splits(self, proxy=None):\n",
        "        if self._history is None:\n",
        "            self.history(period=\"max\", proxy=proxy)\n",
        "        splits = self._history[\"Stock Splits\"]\n",
        "        return splits[splits != 0]\n",
        "\n",
        "    def get_actions(self, proxy=None):\n",
        "        if self._history is None:\n",
        "            self.history(period=\"max\", proxy=proxy)\n",
        "        actions = self._history[[\"Dividends\", \"Stock Splits\"]]\n",
        "        return actions[actions != 0].dropna(how='all').fillna(0)\n",
        "\n",
        "    def get_isin(self, proxy=None):\n",
        "        # *** experimental ***\n",
        "        if self._isin is not None:\n",
        "            return self._isin\n",
        "\n",
        "        ticker = self.ticker.upper()\n",
        "\n",
        "        if \"-\" in ticker or \"^\" in ticker:\n",
        "            self._isin = '-'\n",
        "            return self._isin\n",
        "\n",
        "        # setup proxy in requests format\n",
        "        if proxy is not None:\n",
        "            if isinstance(proxy, dict) and \"https\" in proxy:\n",
        "                proxy = proxy[\"https\"]\n",
        "            proxy = {\"https\": proxy}\n",
        "\n",
        "        q = ticker\n",
        "        self.get_info(proxy=proxy)\n",
        "        if \"shortName\" in self._info:\n",
        "            q = self._info['shortName']\n",
        "\n",
        "        url = 'https://markets.businessinsider.com/ajax/' \\\n",
        "              'SearchController_Suggest?max_results=25&query=%s' \\\n",
        "            % urlencode(q)\n",
        "        data = _requests.get(url=url, proxies=proxy).text\n",
        "\n",
        "        search_str = '\"{}|'.format(ticker)\n",
        "        if search_str not in data:\n",
        "            if q.lower() in data.lower():\n",
        "                search_str = '\"|'.format(ticker)\n",
        "                if search_str not in data:\n",
        "                    self._isin = '-'\n",
        "                    return self._isin\n",
        "            else:\n",
        "                self._isin = '-'\n",
        "                return self._isin\n",
        "\n",
        "        self._isin = data.split(search_str)[1].split('\"')[0].split('|')[0]\n",
        "        return self._isin\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}